{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    '''Wielowarstwowy perceptron (1 warstwa ukryta)'''\n",
    "    def __init__(self, n_in, n_hid, n_out):\n",
    "        \n",
    "        # liczba neuronów w kolejnych warstwach\n",
    "        self.n_in, self.n_hid, self.n_out = n_in, n_hid, n_out\n",
    "\n",
    "        # stany neuronów\n",
    "        self.S_out=zeros(n_out)         # O_i\n",
    "        self.S_hid=zeros(n_hid)         # V_j\n",
    "        self.S_in=zeros(n_in+1)         # ξ_k\n",
    "        self.S_in[-1]=1                 # bias node\n",
    "\n",
    "        # pola lokalne\n",
    "        self.h_hid=zeros(n_hid)         # h_j\n",
    "        self.h_out=zeros(n_out)         # h_i\n",
    "\n",
    "        # wagi połączeń\n",
    "        self.W_ih=zeros((n_in+1,n_hid)) # w_jk - odwrócona kolejność indeksów\n",
    "        self.W_ho=zeros((n_hid,n_out))  # W_ij - odwrócona kolejność indeksów\n",
    "\n",
    "        # delty\n",
    "        self.dW_ih=zeros((n_in+1,n_hid)) # Δw\n",
    "        self.dW_ho=zeros((n_hid,n_out))  # ΔW\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.W_ih = normal(0, 1, self.W_ih.shape)\n",
    "        self.W_ho = normal(0, 1, self.W_ho.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def f(self, x):\n",
    "        '''Funkcja aktywacji'''\n",
    "#         return 1/(1+exp(-x))  # exp zwraca NaN dla dużych arg.\n",
    "        return (tanh(x/2)+1)/2  # to samo co wyżej, ale działa\n",
    "\n",
    "    def Df(self, x):\n",
    "        '''Pochodna funkcji aktywacji'''\n",
    "        y=self.f(x)\n",
    "        return y*(1-y)\n",
    "\n",
    "    def feed(self, inp):\n",
    "        '''Przekazuje wektor danych do warstwy wejściowej'''\n",
    "        self.S_in[:self.n_in]=inp\n",
    "\n",
    "    def forward(self):\n",
    "        '''Propaguje sygnał poprzez kolejne warstwy sieci'''\n",
    "        self.h_hid = self.S_in @ self.W_ih     # h_j\n",
    "        self.S_hid = self.f(self.h_hid)        # g(h_j)\n",
    "        self.h_out = self.S_hid @ self.W_ho    # h_i\n",
    "        self.S_out = self.f(self.h_out)        # g(h_i)\n",
    "        \n",
    "    def diff(self, p):\n",
    "        return self.trainData[p,self.n_in:] - self.S_out\n",
    "\n",
    "    def error(self,p):\n",
    "        return sum(self.diff(p)**2)/2\n",
    "    \n",
    "    def setTrainData(self,data):\n",
    "        '''Zapamiętuje referencję do wektorów uczących'''\n",
    "        self.trainData=data\n",
    "\n",
    "    def eval(self,inp):\n",
    "        self.feed(inp)\n",
    "        self.forward()\n",
    "        return self.S_out\n",
    "\n",
    "    def train(self, eta):\n",
    "        '''Jedna epoka.'''\n",
    "    \n",
    "        Er=0\n",
    "        p_num=self.trainData.shape[0]\n",
    "\n",
    "        self.dW_ih.fill(0)\n",
    "        self.dW_ho.fill(0)\n",
    "\n",
    "#         for p in range(p_num):\n",
    "        for p in random.permutation(p_num):\n",
    "            self.feed(self.trainData[p,:self.n_in])\n",
    "            self.forward()\n",
    "        \n",
    "            self.delta_out = self.Df(self.h_out)*self.diff(p)                   # δ_i\n",
    "            self.dW_ho += outer(self.S_hid, self.delta_out)                     # ΔW_ij\n",
    "            self.delta_hid = self.Df(self.h_hid)*(self.W_ho @ self.delta_out)   # δ_j\n",
    "            self.dW_ih += outer(self.S_in, self.delta_hid)                      # Δw_jk\n",
    "\n",
    "            Er+=self.error(p)\n",
    "\n",
    "        self.W_ih+=eta*self.dW_ih\n",
    "        self.W_ho+=eta*self.dW_ho\n",
    "        return Er   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=array([\n",
    "    [0,0,0,0,1,1,1,1,1,1,0], #0\n",
    "    [0,0,0,1,0,1,1,0,0,0,0], #1\n",
    "    [0,0,1,0,1,1,0,1,1,0,1], #2\n",
    "    [0,0,1,1,1,1,1,1,0,0,1], #3\n",
    "    [0,1,0,0,0,1,1,0,0,1,1], #4\n",
    "    [0,1,0,1,1,0,1,1,0,1,1], #5\n",
    "    [0,1,1,0,1,0,1,1,1,1,1], #6\n",
    "    [0,1,1,1,1,1,1,0,0,0,0], #7\n",
    "    [1,0,0,0,1,1,1,1,1,1,1], #8\n",
    "    [1,0,0,1,1,1,1,1,0,1,1], #9\n",
    "    [1,0,1,0,1,1,1,0,1,1,1], #A\n",
    "    [1,0,1,1,0,0,1,1,1,1,1], #B\n",
    "    [1,1,0,0,1,0,0,1,1,1,0], #C\n",
    "    [1,1,0,1,0,1,1,1,1,0,1], #D\n",
    "    [1,1,1,0,1,0,0,1,1,1,1], #E\n",
    "    [1,1,1,1,1,0,0,0,1,1,1]  #F\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=mlp(4, 15, 7)\n",
    "m.setTrainData(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset()\n",
    "hist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta=1\n",
    "for epoch in range(1000):\n",
    "    hist.append(m.train(eta))\n",
    "print(hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcd(segments):\n",
    "    pixels=[[1,2], [7,11], [19,23], [25,26],\n",
    "              [16,20], [4,8], [13,14]]\n",
    "    d=zeros(4*7)\n",
    "    for s in range(7):\n",
    "        if segments[s]:\n",
    "            d[pixels[s]]=1\n",
    "    imshow(d.reshape(7,4));\n",
    "\n",
    "ints=[[0,0,0,0], [0,0,0,1], [0,0,1,0], [0,0,1,1], \n",
    " [0,1,0,0], [0,1,0,1], [0,1,1,0], [0,1,1,1], \n",
    " [1,0,0,0], [1,0,0,1], [1,0,1,0], [1,0,1,1], \n",
    " [1,1,0,0], [1,1,0,1], [1,1,1,0], [1,1,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots(4,4)\n",
    "plt=1\n",
    "for i in ints:\n",
    "    subplot(4,4,plt)\n",
    "    lcd(m.eval(i)>0.5)\n",
    "    plt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# pickle.dump(m, open('7seg.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "# m=pickle.load(open('7seg.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
