{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP - Multilayer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    '''Wielowarstwowy perceptron (1 warstwa ukryta)'''\n",
    "    def __init__(self, n_in, n_hid, n_out):\n",
    "        \n",
    "        # liczba neuronów w kolejnych warstwach\n",
    "        self.n_in, self.n_hid, self.n_out = n_in, n_hid, n_out\n",
    "\n",
    "        # stany neuronów\n",
    "        self.S_out=zeros(n_out)         # O_i\n",
    "        self.S_hid=zeros(n_hid)         # V_j\n",
    "        self.S_in=zeros(n_in+1)         # ξ_k\n",
    "        self.S_in[-1]=1                 # bias node\n",
    "\n",
    "        # pola lokalne\n",
    "        self.h_hid=zeros(n_hid)         # h_j\n",
    "        self.h_out=zeros(n_out)         # h_i\n",
    "\n",
    "        # wagi połączeń\n",
    "        self.W_ih=zeros((n_in+1,n_hid)) # w_jk - odwrócona kolejność indeksów\n",
    "        self.W_ho=zeros((n_hid,n_out))  # W_ij - odwrócona kolejność indeksów\n",
    "\n",
    "        # delty\n",
    "        self.dW_ih=zeros((n_in+1,n_hid)) # Δw\n",
    "        self.dW_ho=zeros((n_hid,n_out))  # ΔW\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.W_ih = normal(0, 1, self.W_ih.shape)\n",
    "        self.W_ho = normal(0, 1, self.W_ho.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def f(self, x):\n",
    "        '''Funkcja aktywacji'''\n",
    "#         return 1/(1+exp(-x))  # exp zwraca NaN dla dżych arg.\n",
    "        return (tanh(x/2)+1)/2  # to samo co wyżej, ale działa\n",
    "\n",
    "    def Df(self, x):\n",
    "        '''Pochodna funkcji aktywacji'''\n",
    "        y=self.f(x)\n",
    "        return y*(1-y)\n",
    "\n",
    "    def feed(self, inp):\n",
    "        '''Przekazuje wektor danych do warstwy wejściowej'''\n",
    "        self.S_in[:self.n_in]=inp\n",
    "\n",
    "    def forward(self):\n",
    "        '''Propaguje sygnał poprzez kolejne warstwy sieci'''\n",
    "        self.h_hid = self.S_in @ self.W_ih     # h_j\n",
    "        self.S_hid = self.f(self.h_hid)        # g(h_j)\n",
    "        self.h_out = self.S_hid @ self.W_ho    # h_i\n",
    "        self.S_out = self.f(self.h_out)        # g(h_i)\n",
    "        \n",
    "    def diff(self, p):\n",
    "        return self.trainData[p,self.n_in:] - self.S_out\n",
    "\n",
    "    def error(self,p):\n",
    "        return sum(self.diff(p)**2)/2\n",
    "    \n",
    "    def setTrainData(self,data):\n",
    "        '''Zapamiętuje referencję do wektorów uczących'''\n",
    "        self.trainData=data\n",
    "\n",
    "    def eval(self,inp):\n",
    "        self.feed(inp)\n",
    "        self.forward()\n",
    "        return self.S_out\n",
    "\n",
    "    def train(self, eta):\n",
    "        '''Jedna epoka.'''\n",
    "    \n",
    "        Er=0\n",
    "        p_num=self.trainData.shape[0]\n",
    "\n",
    "        self.dW_ih.fill(0)\n",
    "        self.dW_ho.fill(0)\n",
    "\n",
    "        for p in range(p_num):\n",
    "            self.feed(self.trainData[p,:self.n_in])\n",
    "            self.forward()\n",
    "        \n",
    "            self.delta_out = self.Df(self.h_out)*self.diff(p)                   # δ_i\n",
    "            self.dW_ho += outer(self.S_hid, self.delta_out)                     # ΔW_ij\n",
    "            self.delta_hid = self.Df(self.h_hid)*(self.W_ho @ self.delta_out)   # δ_j\n",
    "            self.dW_ih += outer(self.S_in, self.delta_hid)                      # Δw_jk\n",
    "\n",
    "            Er+=self.error(p)\n",
    "\n",
    "        self.W_ih+=eta*self.dW_ih\n",
    "        self.W_ho+=eta*self.dW_ho\n",
    "        return Er   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR\n",
    "# wzorce postaci [in_1, in_2, out_1]\n",
    "pat=array([[0,0,0],[0,1,1],[1,0,1],[1,1,0]])\n",
    "m=mlp(2, 5, 1)\n",
    "m.setTrainData(pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.reset()\n",
    "hist=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta=1\n",
    "for epoch in range(1000):\n",
    "    hist.append(m.train(eta))\n",
    "print(hist[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10 # rozdzielczość\n",
    "z=zeros((n,n))\n",
    "x=linspace(0,1,n)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        z[i,j]=m.eval([x[j],x[i]])\n",
    "figsize(5,5)\n",
    "contourf(x,x,z, vmin=0, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval([0,0]), m.eval([0,1]), m.eval([1,0]), m.eval([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
